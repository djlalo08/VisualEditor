Let's define an annotated list --
    It is simply the following tuple (list, map<str, str>)
    The map represents metadata related to the list in question
Let's also define annotated tuple
    (a, b, c, ... n, map<str, str>)

We'll denote something is annotated with the @ sign
So @list is an annotated list
@(a, b) is an (a,b) that is annotated

Then we can define maps as 
    @(@list, @list)
    Which is the same as
    ( (list, map<str, str>), (list, map<str,str>), map<str,str> )

    Basically a map a list of ins (which are collectively annotated), a list of outs (also annotated), and has its own annotations
    
    If we call eval on an @(@list, @list), we get the resulting computations
    
How do wires factor into this context? 
We don't want to be forced to always inline. I think this is similar to let in LISP

Yes, they are the same.
So this really is a "lisp-visualizer"

The whole point is if we call the type M = @(@list, @list),
The more precise way to define it is as M = @(@list<M>, @list<M>)

Which is to say, that whereas in LISP everything is a list, in POO, everything is an M (map).

so eval is a magic function that takes an M and gives out a list of results?
I don't think that's true, actually...it gives back a list of bindings.
Every vertical and horizontal is an implicit let, where the "variables" defined are the outs.

So here ins  => params
        outs => bindings (of results)
        
The bindings are accessible anywhere "after".
How do we make sense of "after" in this language?

So I guess there _is_ a second construct in our language.
Lists of Ms are legal constructs, and are themselves evaluable.

Maybe we should build such a lisp as an exercise and then build from there.

So the idea is that there are 2 types lists: sequential lists and parallel lists, and our eval() will evaluate those differently. That will be helpful for handling parallelism later on too.

so let's call them s_list and p_list
In and outs are p_lists, because any given in or out doesn't have access to any other
Maps in sequence are in a s_lists, because the second map can access the bindings made in the first map

So now we revise:
(while doing this we notice that outs are just bindings, so they aren't maps, they are just a @p_list<@str>)

M = @s_list< @( @p_list<M>, @p_list<@str> )>

So evaluating an M basically creates a bunch of bindings for it, and then those bindings can be accessed to find values

The whole point is that we have a data structure here (it is a bit more complex than lists), which defines our entire language convention. It means we can natively build Ms as bits of data in our language and it means that metaprogramming is the same thing as M-manipulation.

If we just recognize that all types listed have annotations, we can omit the @ sign:
M = s_list< (p_list<M>, p_list<str>)>
If we do the further syntactical clean-up of:
s_list<x> = [x]
p_list<x> = <x>

We get:
M = [(<M>, <str>)]

So now, so long as we can manipulate s_lists, p_lists, 2-tuples, and strings, we can manipulate arbitrary expressions. That is, we can metaprogram

So we can take a fn that takes an M with the following signature:
M = [(<m1, m2>, <s1, s2>)]
And gives us 
M' = [(<m2, m1>, <s2, s1>)]
In reality, since maps give us bindings, this wouldn't actually return M', it would simply bind our new desired map to M'

For example, say the map is F.
Then F = [(<M>, <M'>)]
So if we have a program:

[
    
    F(<M>, <M'>),
    M(<1,2>, <M_val>),
    M'(<2,1>, <M'_val>)

]
The F, M, M' before the tuples are coming from the @ in the M

Realization! M is actually what we've been calling a Node, not a Map.

So let's update hwo we're speaking and try again.

In particular:

N = [(<N|str>, <str>)]
we let M = (<N|str>, <str>)

So we can define in 2 rules:
N = [M]
M = (<N|str>, <str>)

Both ways are equivalent. It is still a single data structure that eval expects, we're just naming a sub-piece for convenience.

So we try again:

[
    EVAL(
        <[
            INS(<[]>, <a,b>),
            sub(<[a,b]>, <x>)
        ]>, 
        <M>
    )
    F(<[M]>, <M'>),
    M(<[1,2]>, <M_val>),
    M'(<[2,1]>, <M'_val>)
]

Where EVAL(...)
Would be shortened to
DEF( )

All macros would likely be M's and likely follow the form -- ins and outs

M(<[1,2]>, <M_val>),
is the same as 
let M_val = M(1, 2)

F(<[M], <M'>)
is the same as
let M' = F(M)
simply understanding that F is a fn that expects a fn as arg

But how do we define a fn?
That would be the same as making a [(<N>, <str>)]

So we can do:
let M =
[
(
< a, b > //these are special ins because they don't actually exist
    ,
<
>
)
]

sqr(<a>, <a2>)
sub(<a,b>, <s>)

How can we compose these into a new fn?

The point is when we write a fn that's fn evaluation, and the evaluation results in binding the results to bindings (outwires)

So what we want to do is to bind a [(<N>, <str>)] to a binding.
So we need unspecified bindings or "free variables".


Let's define identity or copy, like so:
I(<a>, <b>)
binds a to b. 
Same as 
let b = a;

I think we can use Identity make a map

So we get
I(<sub(<sqr(<a>, <a2>), b>, <x>)>, <M>)
with a, b as "free variables"
and x as a "to be bound" sort of thing

We can then modify M simply as a data structure
So the idea is any function defined as above can have any number of free ins (a,b) and free outs (x). 
The actual resulting map M, is a map that takes 2 inputs (a, b) and returns one output (x). 

Now remember that all this does is bind the name M to the function (a,b) => a^2-b. 
So we might want to have something like 
I(<sub(<sqr(<a>, <a2>), b>, <x>)>, <M>),
M(<4,5>, <z>)

It's just important to keep the visuals in mind here. The <M> on the first line is a wire. The <M> on the second line, we want to look like a Map. How do we do this -- we make a visual transition: it is an exception in the UI.

Whenever we have an object (wire) that meets the type criterion for being an M, we can choose to apply it. This makes it look like a map.

Basically this is the difference between function application and function definition. Lines above would translate like this:
let M = (a,b) => a^2-b
let z = M(4,5);

Point is, syntax for defining and applying a function is different. Similarly, the "visual syntax" is also different between definining vs applying.

I also have an idea for the visual syntax we can use. See mock-ups in this check-in.

I think I know what I'm doing now!

Genius idea! Verticals and Horizontals don't need to exist! Verticals and horizontals are really just s_lists, and they have an attribute that tells direction

And I guess there is the stipulation then that in
N = [(<N|str>, <str>)] 
The outer s_list can actually be arbitrarily many nested s_lists (You can have a vertical in a horizontal in a vertical)
I don't really like this and it seems to complicate things tho. I need to think on it a bit...

V
    H
        A
        B
        C
    H
        V
            H
                A+B -> x
                C*C -> y
            H
                x-y -> z
    H
        z+2


[
    [A,B,C]
    [
        [
            [A+B->x, C*C->y],
            [x-y->z]
        ]
    ]
    [z+2]
]

I think we can just flatten all the way down, and it will work. I can't prove it, but on inspection it looks like it would work in most cases.
i.e:
    [A, B, C, A+B->x, C*C->y, x-y->z, z+2]
Is valid as an s_list

So we have the really only two things that need to be done to go from IR to my internal lisp -- flatten all s_lists. Obviously Ins and Outs gets replaced with a tuple and other obvious transformations are taken care of

We need to consider if collapsing s_lists is going to cause problems...
Is this a new data structure? A list where later elements _depend_ on prior ones? There might be some real algorithms applications of this, but that's besides the point I guess.

Let's say we are using nested s_lists as part of some algorithm -- collapsing them at runtime likely _isn't_ what we want. 

I guess we can collapse only nested s_lists that are marked as Vertical/Horizontal....
That's actually a super simple solution, and I don't feel too bad about it.
It's one slight edge case. I think it's ok.

This does mean that code is not 1-to-1 translatable to IR. Every IR produces an unambiguous code that is always the same, but going from IR to lisp is lossy, in that we lose vertical/horizontal information. All we know is which maps can access which. 

This also have a weird effect -- Nodes next to each other are actually in sequence. That isn't actually what we want. We want horizontals to be p_lists...

I do also think that we really _do_ want Horizontals to be p_lists for parallel computing reasons. You can't have two parallel processes as part of the same s_list, that gives race conditions

Does this mean that we have to include more p_lists are part of our definition...that sounds awful...

Now it starts getting complicated and I have to think about it a bit more

I guess we need a new symbol.
{} means any number of s_lists, with any number of p_lists, with any number of s_lists, etc

With this in mind:
N = {(<N|str>, <str>)}

I guess? 
Suddenly, it's become a bit confusing...

Another thing we can do is simulate Horizontals with pass-through maps, and then hide it under visual syntactic sugar...
That might be much simpler language-wise

For example, 
[
    H(<A,B,C,D>, <a,b,c,d>),
    sum(<a,b,c,d>, x)

]
A B C D are all parallel, in same row, horizontal.

Yeah I like this way of doing it.

Ok so we're back to good old

N = [(<N|bind>, <bind>)]

Ok great. So now we know how to translate Vs and Hs.
V -> []
H -> identity map

Another value of this approach is that for designating parallel code vs code that is horizontal just for legibility, we can just use a different horizontal map

So the big example way above becomes:
V
    H
        A
        B
        C
    H
        V
            H
                A+B -> x
                C*C -> y
            H
                x-y -> z
    H
        z+2

[
    H(<A,B,C>, <A,B,C>),
    H(<[
        H(<[
            sum(<A,B>, <x>),
            mul(<C,C>, <y>)
        ]>, <x,y>),
        H(<[sub(<x,y>, <z>)]>, <z>)        
    ]>, <z>),
    H(<[sum(<z,2>)]>, <out>)
]

Another thing I've been thinking but forgot to write down -- this is all lazy evaluation. It means that things are only pulled as needed. So running a (pure) program, results in no output or result or anything, but attempting to access some binding in the program, will "trickle up" to the beginning.

This sort of tells us how actual evaluation works too -- as soon as someone tries to access a node (in a map) that node is computed based on the map that it is an output of - of course, we might not yet know what the inputs of the map evaluate to, so we need to evalute each of the inputs, and so on.
This allows us to cache results really easy. 
It might be inefficient to propagate up and back down (like maybe we build a big stack of something), but we're going to go with it for now -- I suspect it will actually perform decently

Another note: the binding type has an attribute that is either "free" or "concrete". For example in line 180, most of those variables are free, because they are not yet determined. I think in practice of evaluationg no real distinction needs to be made, it's just useful for the programmer to be able to distinguish, so we could show them in different colors for example and if something that is labelled as concrete is never defined, throw an error or if something labelled as free is defined, throw an error

Another note, an H can have a gazillion possible outputs.
There is a convention for H's -- output bindings have a value attr which tells us which things it is actually outputting


Here is the above example a bit more fleshed out:
[
H(<A:f,B:f,C:f>, <A1,B1,C1>),
H(<[
    H(<[
        sum(<A1:c,B1:c>, <x>),
        mul(<C1:c,C1:c>, <y>)
    ]>, <x1:v=x,y1:v=y>),
    H(<[sub(<x1,y1>, <z>)]>, <z1:v=z>)        
]>, <z2:v=z1>),
H(<[sum(<z2,2>)]>, <out>)
]

Let's make a super simple example program:
eval[
    name:Id,map(ins<3 4> outs<A B>)
    name:sum,map(ins<A:c B:c> outs<c>)
    name:print,map(ins<c> outs<>)
]

As IR:
Node
    Map:id
        Ins
            constant:3
            constant:4 
        Outs
            binding:A
            binding:B
    Map:sum
        Ins
            binding:A,concrete
            binding:B,concrete
        Outs
            binding:c
    Map:print,impure
        Ins
            binding:c
        Outs
        
So we need to identify normal lists vs actual nodes. How? We can use annotations! So if we have a normal N-type, we add a Node annotation and now it is executable instead! This can happen in our expansion where we do fn definition vs fn declaration. 

So for actual compilation it's actually very straight-forward. At compile-time we just link up all bindings (might have to think a bit about free bindings for this...). So in the simple example, compiler replaces input <c> with input <sum(<A, B>)[0]>. So now in runtime, we do trickle-up.
Just a small note, but we aren't actually making copies of c, we just use a pointer.

So for now evalution happens _outside_ of the program (there is no print map). And we'll have to figure out actual impure functions later

By the way, fileinput/fileoutput don't actually exist. We simply have free or concrete bindings (for in or out) and they can be anywhere -- any bindings that are free (at the file level) are considered the in/outputs for the file


How to write compiler:
    Assume You have a map.
    How do we evaluate it?
        -First evaluate each of the inputs
            -Have to determine whether an input is a primitive/constant, binding, or a map:
                -For primitive/constant, just parse and return the value
                -For binding, find the setvalue with the same id as input's getvalue. This will be the output of a map. In order to determine it, evaluate said map
                -For map, evaluate map. Map attrs should specify which output we are using, return that specific one
        -Then apply the map to those values
            This is function evaluation. 
                -If we have a fn name, lookup that function and apply it
                    -It might be a built-in function like addition (then it will just perform the specified fn)
                    -It might a function defined in some other file. Pull up corresponding file and evaluate the free output variables of that fn that are in use as below
                -If it is an N or a defined function, associate the free outputs with the outputs that we are actually using. Associate the free inputs with the inputs that we are actually using. Then evaluate the outputs like normal (by evalutating ins and applying fn to them)
        -Return the results as a list
            -Probably straightforward?